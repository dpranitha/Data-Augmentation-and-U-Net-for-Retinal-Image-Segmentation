# -*- coding: utf-8 -*-
"""Major Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JAcG9KTpuD5haHM_VXXO4oRe6u80b1nP

# Preprocess for Drive Dataset
"""

!git clone https://github.com/guyuchao/Vessel-wgan-pytorch.git

!pip uninstall opencv-python-headless==4.5.5.62

!pip install opencv-python-headless==4.5.2.52

import cv2
import os
import h5py
import numpy as np
from PIL import Image

from google.colab import drive
drive.mount('/content/drive')

TRAIN_IMG = "/content/drive/MyDrive/major/data/train/images"
TRAIN_LABEL = "/content/drive/MyDrive/major/data/train/labels"

TEST_IMG = "/content/drive/MyDrive/major/data/test/images"
TEST_LABEL = "/content/drive/MyDrive/major/data/test/labels"

images_train = "/content/Vessel-wgan-pytorch/eyedata/train/img"
labels_train = "/content/Vessel-wgan-pytorch/eyedata/train/label"

Nimgs = 20
channels = 1
height = 584
width = 565

imgs = np.empty((Nimgs,height,width,channels))
lbls = np.empty((Nimgs,height,width))

i=0
for file in sorted(os.listdir(images_train)):
  img = cv2.imread(images_train+'/'+file, 0)
  img = np.expand_dims(img, axis=0)
  img = np.moveaxis(img,0, -1)
  #print(img.shape)
  imgs[i] = img
  i += 1

i=0
for file in sorted(os.listdir(labels_train)):
  g_truth = Image.open(labels_train +'/'+ file)
  lbls[i] = np.asarray(g_truth)
  i += 1

print(imgs.shape)
print(lbls.shape)

for i in range(20):
  cv2.imwrite(TRAIN_IMG + '/' + str(i) + '.png', imgs[i])

for i in range(20):
  cv2.imwrite(TRAIN_LABEL + '/' + str(i) + '.png', lbls[i])

images_test = "/content/Vessel-wgan-pytorch/eyedata/val/img"
labels_test = "/content/Vessel-wgan-pytorch/eyedata/val/label"

Nimgs = 20
channels = 1
height = 584
width = 565

imgs = np.empty((Nimgs,height,width,channels))
lbls = np.empty((Nimgs,height,width))

i=0
for file in sorted(os.listdir(images_test)):
  img = cv2.imread(images_test+'/'+file, 0)
  img = np.expand_dims(img, axis=0)
  img = np.moveaxis(img,0, -1)
  #print(img.shape)
  imgs[i] = img
  i += 1

i=0
for file in sorted(os.listdir(labels_test)):
  g_truth = Image.open(labels_test +'/'+ file)
  lbls[i] = np.asarray(g_truth)
  i += 1

print(imgs.shape)
print(lbls.shape)

j = 1
for i in range(20):
  cv2.imwrite(TEST_IMG + '/' + str(j) + '.png',imgs[i])
  j += 1

j = 1
for i in range(20):
  cv2.imwrite(TEST_LABEL + '/' + str(j) + '.png',lbls[i])
  j += 1

from google.colab.patches import cv2_imshow
cv2_imshow(imgs[0])
cv2_imshow(lbls[0])

"""# Augmentation for segmentation Task"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install clodsa
# !pip install -q -U albumentations

!pip uninstall imgaug

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install git+https://github.com/aleju/imgaug.git

from matplotlib import pyplot as plt
#from clodsa.augmentors.augmentorFactory import createAugmentor
#from clodsa.transformers.transformerFactory import transformerGenerator
#from clodsa.techniques.techniqueFactory import createTechnique
import random
import cv2
import albumentations as A
import imageio
import imgaug as ia
import imgaug.augmenters as iaa
import os

"""### Rotation"""

input_path = '/content/drive/MyDrive/major/data/train'
output_path = '/content/drive/MyDrive/major/png_data/rotation'

!pip install tifffile 
!pip install imagecodecs 
import numpy 
import tifffile as tiff

def rotation(degree, input_path, output_path, image_count):
  images = []
  labels = []
  for img_path in range(image_count):
    img = imageio.imread(input_path + '/images/' + str(img_path) + '.png')
    images.append(img) 

    lbl = imageio.imread(input_path + '/labels/' + str(img_path) + '.png')
    labels.append(lbl)
  
  seq = iaa.Sequential(
      [

          iaa.Rotate((degree)),

      ]
  )

  images_aug = seq(images=images)
  labels_aug = seq(images=labels)

  path = os.path.join(output_path, 'images') 
  os.mkdir(path) 

  path = os.path.join(output_path, 'labels') 
  os.mkdir(path)

  for indx, i in enumerate(images_aug):
      imageio.imwrite(output_path + '/images/'  + 'rotat'+ '_' + str(indx) + '.png', i)

  for indx, i in enumerate(labels_aug):
      imageio.imwrite(output_path + '/labels/'  + 'rotat'+ '_' + str(indx) + '.png', i)

  print("Rotation results were saved given directory.")

rotation(30,input_path,output_path,20)

"""### JPEG Compression"""

import imageio
import imgaug as ia
import os 

def apply_jpeg_compression(input_path, output_path, degrees):

  images = []
  labels = []

  for img_path in range(20):
    img = imageio.imread(input_path + '/images/' + str(img_path) + '.png')
    images.append(img) 

    lbl = imageio.imread(input_path + '/labels/' + str(img_path) + '.png')
    labels.append(lbl)

  for degree in degrees:
    aug = ia.augmenters.JpegCompression(compression=degree)
    
    images_aug = aug.augment_images(images=images)
    for indx, i in enumerate(images_aug):
      imageio.imwrite(output_path + 'jpegcomp' + str(degree) + '/images/'  + str(indx) + '.png', i)

    labels_aug = aug.augment_images(images=labels)
    for indx, i in enumerate(labels_aug):
      imageio.imwrite(output_path + 'jpegcomp' + str(degree) + '/labels/'  + str(indx) + '.png', i)

  print("JPEG Compression results were saved given directory.")

# 25,50,75 should be in seperate folders

apply_jpeg_compression("/content/drive/MyDrive/major/data/train",
                       "/content/drive/MyDrive/major/png_data/", [25,50,75])

"""### Zoom In / Out"""

input_path = '/content/drive/MyDrive/major/data/train'
output_path = '/content/drive/MyDrive/major/png_data/zoom'

def zoom(zoom_amount, input_path, output_path, image_count):
  images = []
  labels = []
  ia.seed(1)
  for img_path in range(image_count):
    img = imageio.imread(input_path + '/images/' + str(img_path) + '.png')
    images.append(img) 

    lbl = imageio.imread(input_path + '/labels/' + str(img_path) + '.png')
    labels.append(lbl)
  
  seq = iaa.Sequential(
      [

          iaa.Affine(
              scale={"x": (zoom_amount), "y": (zoom_amount)}
          ),

      ]
  )

  images_aug = seq(images=images)
  labels_aug = seq(images=labels)

  for indx, i in enumerate(images_aug):
      imageio.imwrite(output_path + str(zoom_amount)  + '/images/' + 'zoom_' + str(indx) + '.png', i)

  for indx, i in enumerate(labels_aug):
      imageio.imwrite(output_path + str(zoom_amount)  + '/labels/'  + 'zoom_' + str(indx) + '.png', i)

  print("Zoom results were saved given directory.")

zoom(0.8, input_path, output_path, 20)

zoom(1.2, input_path, output_path, 20)

"""### Shear X/Y"""

input_path = '/content/drive/MyDrive/major/data/train'
output_path = '/content/drive/MyDrive/major/png_data/shearX'

def shearX(shear_amount, input_path, output_path, image_count):
  images = []
  labels = []
  ia.seed(1)
  for img_path in range(image_count):
    img = imageio.imread(input_path + '/images/' + str(img_path) + '.png')
    images.append(img) 

    lbl = imageio.imread(input_path + '/labels/' + str(img_path) + '.png')
    labels.append(lbl)
  
  seq = iaa.Sequential(
      [

          iaa.ShearX((shear_amount)),

      ]
  )

  images_aug = seq(images=images)
  labels_aug = seq(images=labels)

  for indx, i in enumerate(images_aug):
      imageio.imwrite(output_path + '/images/'  + 'shearX_' + str(indx) + '.png', i)

  for indx, i in enumerate(labels_aug):
      imageio.imwrite(output_path + '/labels/'  + 'shearX_' + str(indx) + '.png', i)

  print("Shear results were saved given directory.")

def shearY(shear_amount, input_path, output_path, image_count):
  images = []
  labels = []
  ia.seed(1)
  for img_path in range(image_count):
    img = imageio.imread(input_path + '/images/' + str(img_path) + '.png')
    images.append(img) 

    lbl = imageio.imread(input_path + '/labels/' + str(img_path) + '.png')
    labels.append(lbl)
  
  seq = iaa.Sequential(
      [

          iaa.ShearY((shear_amount)),

      ]
  )

  images_aug = seq(images=images)
  labels_aug = seq(images=labels)

  for indx, i in enumerate(images_aug):
      imageio.imwrite(output_path + '/images/'  + 'shearY_' + str(indx) + '.png', i)

  for indx, i in enumerate(labels_aug):
      imageio.imwrite(output_path + '/labels/'  + 'shearY_' + str(indx) + '.png', i)

  print("Shear results were saved given directory.")

shearX(20, input_path, output_path, 20)

output_path = '/content/drive/MyDrive/major/png_data/shearY'
shearY(20, input_path, output_path, 20)

"""### Contrast"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install imagecorruptions

input_path = '/content/drive/MyDrive/major/data/train'
output_path = '/content/drive/MyDrive/major/png_data/contrast'

def contrast(severity, input_path, output_path, image_count):
  images = []
  labels = []

  for img_path in range(image_count):
    img = imageio.imread(input_path + '/images/' + str(img_path) + '.png')
    images.append(img) 

    lbl = imageio.imread(input_path + '/labels/' + str(img_path) + '.png')
    labels.append(lbl)
  
  seq = iaa.Sequential(
    [

        iaa.imgcorruptlike.Contrast(severity=severity),

    ]
  )

  images_aug = seq(images=images)


  for indx, i in enumerate(images_aug):
      imageio.imwrite(output_path + '/images/'  + 'contrast'+ '_' + str(indx) + '.png', i)

  for indx, i in enumerate(labels):
      imageio.imwrite(output_path + '/labels/'  + 'contrast'+ '_' + str(indx) + '.png', i)

  print("Contrast results were saved given directory.")

contrast(2,input_path, output_path, image_count= 20)

"""### Shift X Y"""

import numpy as np
import imgaug as ia
import imgaug.augmenters as iaa
import imageio
import os

input_path ='/content/drive/MyDrive/major/data/train'
output_path = '/content/drive/MyDrive/major/png_data/shiftX'

shift_amount = -100 #pixel
image_count  = 20

def shiftX(shift_amount, input_path, output_path, image_count):
  images = []
  labels = []

  for img_path in range(image_count):
    img = imageio.imread(input_path + '/images/' + str(img_path) + '.png')
    images.append(img) 

    lbl = imageio.imread(input_path + '/labels/' + str(img_path) + '.png')
    labels.append(lbl)
  
  seq = iaa.Sequential(
    [

        iaa.TranslateX(px=(shift_amount))

    ]
  )

  images_aug = seq(images=images)
  labels_aug = seq(images=labels)

  for indx, i in enumerate(images_aug):
      imageio.imwrite(output_path + '/images/'  + 'shiftX'+ '_' + str(indx) + '.png', i)

  for indx, i in enumerate(labels_aug):
      imageio.imwrite(output_path + '/labels/'  + 'shiftX'+ '_' + str(indx) + '.png', i)

  print("Shift results were saved given directory.")

def shiftY(shift_amount, input_path, output_path, image_count):
  images = []
  labels = []

  for img_path in range(image_count):
    img = imageio.imread(input_path + '/images/' + str(img_path) + '.png')
    images.append(img) 

    lbl = imageio.imread(input_path + '/labels/' + str(img_path) + '.png')
    labels.append(lbl)
  
  seq = iaa.Sequential(
    [

        iaa.TranslateY(px=(shift_amount))

    ]
  )

  images_aug = seq(images=images)
  labels_aug = seq(images=labels)

  for indx, i in enumerate(images_aug):
      imageio.imwrite(output_path + '/images/'  + 'shiftY'+ '_' + str(indx) + '.png', i)

  for indx, i in enumerate(labels_aug):
      imageio.imwrite(output_path + '/labels/'  + 'shiftY'+ '_' + str(indx) + '.png', i)

  print("Shift results were saved given directory.")

shiftX(shift_amount, input_path, output_path, image_count)

input_path ='/content/drive/MyDrive/major/data/train'
output_path = '/content/drive/MyDrive/major/png_data/shiftY/'
shiftY(shift_amount, input_path, output_path, image_count)

"""### Albumentations

Create your main folder in your path<br>
Change the paths inside the code properly<br>
Choose the method from [here](https://albumentations.ai/docs/examples/example_kaggle_salt/)<br>
Change the part between hashtags (####) with this method<br>
Output will be in your main path<br>
"""

import os
import cv2

input_path ='/content/drive/MyDrive/major/data/train'
output_path = '/content/drive/MyDrive/major/png_data/album'
original_height, original_width = 608, 704

print(original_height)
print(original_width)

def albumentation( input_path, output_path, original_height, original_width):

  for img in sorted(os.listdir(input_path + '/images')):

    image = cv2.imread(input_path +'/images/' + img, 0)
    mask  = cv2.imread(input_path +'/labels/' + img, 0)
    
    ##############################################################
    aug = A.Compose([
      A.OneOf([
          A.RandomSizedCrop(min_max_height=(50, 101), height=original_height, width=original_width, p=0.5),
          A.PadIfNeeded(min_height=original_height, min_width=original_width, p=0.5)
      ], p=1),    
      A.VerticalFlip(p=0.5),              
      A.RandomRotate90(p=0.5),
      A.OneOf([
          A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03, p=0.5),
          A.GridDistortion(p=0.5),
          A.OpticalDistortion(distort_limit=2, shift_limit=0.5, p=1)                  
          ], p=0.8),
      A.CLAHE(p=0.8),
      A.RandomBrightnessContrast(p=0.8),    
      A.RandomGamma(p=0.8)])
    ##############################################################

    augmented = aug(image=image, mask=mask)

    image = augmented['image']
    mask = augmented['mask']

    cv2.imwrite(output_path +'/images/' + img, image)
    cv2.imwrite(output_path +'/labels/' + img, mask)

albumentation( input_path, output_path, original_height, original_width)

"""## Append One Directory to Another"""

import os, shutil

def merge_augmentations(augment_dir, output_dir, list_of_aug_files):
  '''
    - augment_dir         (string)   : The path which has subfolders that are augmentation folders.
    - output_dir          (string)   : The path you want to put all augmentations.
    - list_of_aug_files   (list)     : List of names which contains augmentations.
  '''

  for folder in list_of_aug_files:
    if folder != 'train':
      for file in sorted(os.listdir(augment_dir + '/' + folder + '/images')):
        shutil.copy(augment_dir + '/' + folder + '/images/' + file, output_dir + '/images/' + folder + '_' + file.split("_")[-1].split('.')[0] + '.png')
        shutil.copy(augment_dir + '/' + folder + '/labels/' + file, output_dir + '/labels/' + folder + '_' + file.split("_")[-1].split('.')[0] + '.png')
        #shutil.copy(augment_dir + '/' + folder + '/images/' + file, output_dir + '/images/' + file)
        #shutil.copy(augment_dir + '/' + folder + '/labels/' + file, output_dir + '/labels/' + file)
    else:
      for file in sorted(os.listdir(augment_dir + '/' + folder + '/images')):
        shutil.copy(augment_dir + '/' + folder + '/images/' + file, output_dir + '/images/' + file.split("_")[-1].split('.')[0] + '.png')
        shutil.copy(augment_dir + '/' + folder + '/labels/' + file, output_dir + '/labels/' + file.split("_")[-1].split('.')[0] + '.png')
        #shutil.copy(augment_dir + '/' + folder + '/images/' + file, output_dir + '/images/' + file)
        #shutil.copy(augment_dir + '/' + folder + '/labels/' + file, output_dir + '/labels/' + file)

    print(folder + ' folder has been merged...')
    print('Number of images in output: ' + str(len(os.listdir(output_dir + '/images'))))
  
  print('Merging is done successfully!')

merge_augmentations('/content/drive/MyDrive/major/png_data',
                    '/content/drive/MyDrive/major/output_dir', 
           ['album','contrast','jpegcomp25','jpegcomp50','jpegcomp75','rotation','shearX','shearY','shiftX','shiftY','zoom0.8','zoom1.2'])

"""# Training Drive dataset with U_Net Architecture"""

import os
import skimage.io as io
import skimage.transform as trans
import shutil
import cv2
import matplotlib.pyplot as plt
import pickle
import time
from __future__ import print_function
import glob
import tensorflow as tf
import numpy as np
from keras.preprocessing.image import ImageDataGenerator
from keras.models import *
from keras.layers import *
from keras.optimizers import *
from keras.callbacks import ModelCheckpoint, LearningRateScheduler
from keras import backend as keras
from tensorflow.keras.models import load_model as load_initial_model
from google.colab.patches import cv2_imshow
import gc

"""## Handcrafted Metrics For Additional Evaluation"""

def dice_coef(y_true, y_pred):
  smooth = 0.0
  y_true_f = keras.flatten(y_true)
  y_pred_f = keras.flatten(y_pred)
  intersection = keras.sum(y_true_f * y_pred_f)
  return (2. * intersection + smooth) / (keras.sum(y_true_f) + keras.sum(y_pred_f) + smooth)

def jacard(y_true, y_pred):

  y_true_f = keras.flatten(y_true)
  y_pred_f = keras.flatten(y_pred)
  intersection = keras.sum ( y_true_f * y_pred_f)
  union = keras.sum ( y_true_f + y_pred_f - y_true_f * y_pred_f)

  return intersection/union

"""## The Model"""

def unet(pretrained_weights = None,input_size = (608,576,1)):
  inputs = Input(input_size)
  conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)
  conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)
  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
  conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)
  conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)
  pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
  conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)
  conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)
  pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
  conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)
  conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)
  drop4 = Dropout(0.5)(conv4)
  pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)

  conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)
  conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)
  drop5 = Dropout(0.5)(conv5)

  up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))
  merge6 = concatenate([drop4,up6], axis = 3)
  conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)
  conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)

  up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))
  merge7 = concatenate([conv3,up7], axis = 3)
  conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)
  conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)

  up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))
  merge8 = concatenate([conv2,up8], axis = 3)
  conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)
  conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)

  up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))
  merge9 = concatenate([conv1,up9], axis = 3)
  conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)
  conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)
  conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)
  conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)

  model = Model(inputs,conv10)

  model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy',dice_coef,jacard, tf.keras.metrics.AUC(), tf.keras.metrics.MeanIoU(num_classes=2),
                                                                                      tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])
    
  #model.summary()

  if(pretrained_weights):
    model.load_weights(pretrained_weights)

  return model

"""## Generators"""

def adjustData(img,mask,flag_multi_class,num_class):
  if(flag_multi_class):
    img = img / 255
    mask = mask[:,:,:,0] if(len(mask.shape) == 4) else mask[:,:,0]
    new_mask = np.zeros(mask.shape + (num_class,))
    for i in range(num_class):
        #for one pixel in the image, find the class in mask and convert it into one-hot vector
        #index = np.where(mask == i)
        #index_mask = (index[0],index[1],index[2],np.zeros(len(index[0]),dtype = np.int64) + i) if (len(mask.shape) == 4) else (index[0],index[1],np.zeros(len(index[0]),dtype = np.int64) + i)
        #new_mask[index_mask] = 1
        new_mask[mask == i,i] = 1
    new_mask = np.reshape(new_mask,(new_mask.shape[0],new_mask.shape[1]*new_mask.shape[2],new_mask.shape[3])) if flag_multi_class else np.reshape(new_mask,(new_mask.shape[0]*new_mask.shape[1],new_mask.shape[2]))
    mask = new_mask
  elif (np.max(img) > 1):
    img = img / 255
    mask = mask /255
    mask[mask > 0.5] = 1
    mask[mask <= 0.5] = 0
  return (img,mask)

def trainGenerator(batch_size,train_path,image_folder,mask_folder,aug_dict,image_color_mode = "grayscale",
                    mask_color_mode = "grayscale",image_save_prefix  = "image",mask_save_prefix  = "mask",
                    flag_multi_class = False,num_class = 2,save_to_dir = None,target_size = (608,576),seed = 1):
  image_datagen = ImageDataGenerator(**aug_dict)
  mask_datagen = ImageDataGenerator(**aug_dict)
  image_generator = image_datagen.flow_from_directory(
      train_path,
      classes = [image_folder],
      class_mode = None,
      color_mode = image_color_mode,
      target_size = target_size,
      batch_size = batch_size,
      save_to_dir = save_to_dir,
      save_prefix  = image_save_prefix,
      seed = seed)
  mask_generator = mask_datagen.flow_from_directory(
      train_path,
      classes = [mask_folder],
      class_mode = None,
      color_mode = mask_color_mode,
      target_size = target_size,
      batch_size = batch_size,
      save_to_dir = save_to_dir,
      save_prefix  = mask_save_prefix,
      seed = seed)
  train_generator = zip(image_generator, mask_generator)
  for (img,mask) in train_generator:
    img,mask = adjustData(img,mask,flag_multi_class,num_class)
    yield (img,mask)

def testGenerator(test_path, target_size = (608,576),flag_multi_class = False,as_gray = True):
  image_datagen = ImageDataGenerator(rescale=1./255)
  mask_datagen = ImageDataGenerator(rescale=1./255)

  for img_name in sorted(os.listdir(test_path + "/images")):
      img = io.imread(os.path.join(test_path + "/images",img_name),as_gray = as_gray)
      img = img / 255
      img = trans.resize(img,target_size)
      img = np.reshape(img,img.shape+(1,)) if (not flag_multi_class) else img
      img = np.reshape(img,(1,)+img.shape)
      yield img

def testGenerator2(batch_size,test_path,image_folder,mask_folder,aug_dict,image_color_mode = "grayscale",
                    mask_color_mode = "grayscale",image_save_prefix  = "image",mask_save_prefix  = "mask",
                    flag_multi_class = False,num_class = 2,save_to_dir = None,target_size = (608,576),seed = 1):
  image_datagen = ImageDataGenerator(**aug_dict)
  mask_datagen = ImageDataGenerator(**aug_dict)
  image_generator = image_datagen.flow_from_directory(
      test_path,
      classes = [image_folder],
      class_mode = None,
      color_mode = image_color_mode,
      target_size = target_size,
      batch_size = batch_size,
      save_to_dir = save_to_dir,
      save_prefix  = image_save_prefix,
      seed = seed)
  mask_generator = mask_datagen.flow_from_directory(
      test_path,
      classes = [mask_folder],
      class_mode = None,
      color_mode = mask_color_mode,
      target_size = target_size,
      batch_size = batch_size,
      save_to_dir = save_to_dir,
      save_prefix  = mask_save_prefix,
      seed = seed)
  test_generator = zip(image_generator, mask_generator)
  for (img,mask) in test_generator:
    img,mask = adjustData(img,mask,flag_multi_class,num_class)
    yield (img,mask)

"""## Utils"""

def pad(input_folder, output_folder):
  for file in sorted(os.listdir(input_folder)):
    if '.png' in file:
      tmp = cv2.imread(input_folder + '/' + file, 0)
      tmp = cv2.copyMakeBorder(tmp.copy(),12,12,5,6,cv2.BORDER_CONSTANT,value=(0,0,0))
      io.imsave(output_folder + '/' + file, tmp)
  print('Padding is done.')

def crop(input_folder, output_folder):
  for file in sorted(os.listdir(input_folder)):
    if '.png' in file:
      tmp = cv2.imread(input_folder + '/' + file, 0)
      tmp = tmp[12:-12, 5:-6]
      io.imsave(output_folder + '/' + file, tmp)
  print('Cropping is done.')

def saveResult_drive(save_path,npyfile,flag_multi_class = False,num_class = 2):
  for i,item in enumerate(npyfile):
      img = plt.labelVisualize(num_class ,item) if flag_multi_class else item[:,:,0]
      io.imsave(os.path.join(save_path,"%d.png"%(i)),img)

def threshold(folder):
  for img in sorted(os.listdir(folder)):
    tmp = cv2.imread(folder + '/' + img, 0)
    _, tmp = cv2.threshold(tmp,115,255,cv2.THRESH_BINARY)
    io.imsave(folder + '/' + img, tmp)

def set_order(input_folder, output_folder):

  for img in sorted(os.listdir(input_folder)):

    if int(img.split('.')[0]) == 0:
      tmp = cv2.imread(input_folder  + '/' + img, 0)
      io.imsave(output_folder + '/' + str(int(img.split('.')[0])+1) + '.png', tmp)
    elif int(img.split('.')[0]) >= 1 and int(img.split('.')[0]) <= 10:
      tmp = cv2.imread(input_folder  + '/' + img, 0)
      io.imsave(output_folder + '/' + str(int(img.split('.')[0])+9) + '.png', tmp)
    elif int(img.split('.')[0]) >= 13 and int(img.split('.')[0]) <= 19:
      tmp = cv2.imread(input_folder  + '/' + img, 0)
      io.imsave(output_folder + '/' + str(int(img.split('.')[0])-10) + '.png', tmp)
    elif int(img.split('.')[0]) == 11:
      tmp = cv2.imread(input_folder  + '/' + img, 0)
      io.imsave(output_folder + '/' + str(int(img.split('.')[0])-9) + '.png', tmp)
    elif int(img.split('.')[0]) == 12:
      tmp = cv2.imread(input_folder  + '/' + img, 0)
      io.imsave(output_folder + '/' + str(int(img.split('.')[0])+8) + '.png', tmp)

def dice(true_mask, pred_mask, non_seg_score=1.0):
    """
        Computes the Dice coefficient.
        Args:
            true_mask : Array of arbitrary shape.
            pred_mask : Array with the same shape than true_mask.  
        
        Returns:
            A scalar representing the Dice coefficient between the two segmentations. 
        
    """
    assert true_mask.shape == pred_mask.shape

    true_mask = np.asarray(true_mask).astype(np.bool)
    pred_mask = np.asarray(pred_mask).astype(np.bool)

    # If both segmentations are all zero, the dice will be 1. (Developer decision)
    im_sum = true_mask.sum() + pred_mask.sum()
    if im_sum == 0:
        return non_seg_score

    # Compute Dice coefficient
    intersection = np.logical_and(true_mask, pred_mask)
    return 2. * intersection.sum() / im_sum

def mean_dice(true_path, pred_path):
  
  sum = 0
  
  for img in sorted(os.listdir(pred_path)):
    
    true_tmp = cv2.imread(true_path + '/' + img, 0)
    pred_tmp = cv2.imread(pred_path + '/' + img, 0)
    
    a = dice(true_tmp, pred_tmp)
    print(a)
    sum += a
  
  return sum/len(os.listdir(true_path))

"""## DRIVE"""

LOG_PATH      = '/content/drive/MyDrive/major/U-Net/logs'
RESULT_PATH   = '/content/drive/MyDrive/major/U-Net/test_results'
MODEL_PATH    = '/content/drive/MyDrive/major/U-Net/models'

TRAIN_PATH    = '/content/drive/MyDrive/major/output_dir'
VAL_PATH      = '/content/drive/MyDrive/major/data/test'
TEST_PATH     = '/content/drive/MyDrive/major/data/test'

TMP_TRAIN     = '/content/drive/MyDrive/major/U-Net/tmp_train'
TMP_TEST      = '/content/drive/MyDrive/major/U-Net/tmp_test'
TMP_VAL       = '/content/drive/MyDrive/major/U-Net/tmp_val'
TMP_RESULT    = '/content/drive/MyDrive/major/U-Net/tmp_result'

if (os.path.isdir(LOG_PATH) and os.path.isdir(RESULT_PATH) and \
    os.path.isdir(MODEL_PATH) and os.path.isdir(TRAIN_PATH)) and \
    os.path.isdir(TEST_PATH) and os.path.isdir(VAL_PATH) and \
    os.path.isdir(TMP_TRAIN) and os.path.isdir(TMP_TEST) and \
    os.path.isdir(TMP_VAL) and os.path.isdir(TMP_RESULT) == 0:
    raise OSError()

"""## Train many Epochs at once"""

def train_eval_drive(save_name, num_train, num_test, initial_model_path, train_batch = 3, test_batch = 3, epoch = 5):
  
  pad(TRAIN_PATH + '/images', TMP_TRAIN + '/images')
  pad(TRAIN_PATH + '/labels', TMP_TRAIN + '/labels')

  pad(TEST_PATH + '/images', TMP_TEST + '/images')
  pad(TEST_PATH + '/labels', TMP_TEST + '/labels')
  
  pad(VAL_PATH + '/images', TMP_VAL + '/images')
  pad(VAL_PATH + '/labels', TMP_VAL + '/labels')
  
  data_gen_args = dict()
  train_generator = trainGenerator(train_batch, TMP_TRAIN, 'images', 'labels', data_gen_args, save_to_dir = None, target_size=(608,576))
  test_generator = testGenerator2(test_batch, TMP_TEST, 'images', 'labels', data_gen_args, save_to_dir = None, target_size=(608,576))

  model = unet(input_size=(608,576,1))
  if initial_model_path != None:
    model.load_weights(initial_model_path)

  model_checkpoint = ModelCheckpoint(MODEL_PATH + "/" + save_name +".hdf5", monitor='loss',verbose=1, save_best_only=True)

  model_history = model.fit(train_generator, steps_per_epoch=num_train//train_batch, epochs=epoch, callbacks=[model_checkpoint],
                                      validation_data=test_generator, validation_steps=num_test//test_batch)
  
  log_file = open(LOG_PATH + "/log_{}.pkl".format(save_name), "wb")#history file
  pickle.dump(model_history.history, log_file)
  log_file.close()

  test_generator_2 = testGenerator(TMP_TEST, target_size=(608,576))
  results = model.predict_generator(test_generator_2,verbose=1)

  
  saveResult_drive(TMP_RESULT, results)
  
  os.mkdir(RESULT_PATH + '/' + save_name)
  crop(TMP_RESULT, RESULT_PATH + '/' + save_name)

  threshold(RESULT_PATH + '/' + save_name)

  shutil.rmtree(RESULT_PATH + '/download', ignore_errors=False, onerror=None)
  os.mkdir(RESULT_PATH + '/download')
  set_order(RESULT_PATH + '/' + save_name, RESULT_PATH + '/download')

train_sample_number = len(os.listdir(TRAIN_PATH + '/images'))
test_sample_number  = len(os.listdir(TEST_PATH + '/images'))

SAVE_NAME = 'my_model'
INITIAL_MODEL_PATH = None
EPOCH = 1

train_eval_drive(SAVE_NAME, initial_model_path= INITIAL_MODEL_PATH, epoch= EPOCH, train_batch = 3, test_batch = 3, num_train = train_sample_number, num_test= test_sample_number)

log_file = open(LOG_PATH + "/log_" + SAVE_NAME + ".pkl" , "rb")
output = pickle.load(log_file)
i = 0
for key, value in output.items():
  print(key + " --> " + str(value[EPOCH-1]))
  i = i+1
print(50*"-")

